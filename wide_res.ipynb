{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "add_zeropadding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kihongMin/MLDL/blob/master/wide_res.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnrvOU4XyELz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8vDye88QAb3",
        "colab_type": "code",
        "outputId": "902715f7-2432-4d3d-cbf7-f03a60a6800e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone \"https://github.com/parrotProj/proj1.git\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'proj1' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Uyobm1QB6L",
        "colab_type": "code",
        "outputId": "c637759f-3090-4819-8128-c3a04255589c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd proj1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/proj1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jckPbdDQCOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Resize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpTsdsa0zrFr",
        "colab_type": "code",
        "outputId": "7b42a597-8e12-4d95-af3c-950b058d79fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train,Y_train = Resize.train(160)\n",
        "X_test,X_id = Resize.test(160)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_size :  160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__dA1uCpQDgf",
        "colab_type": "code",
        "outputId": "52dd6b32-bead-4256-c24f-de35da203b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y_train = to_categorical(Y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_INn3kBrMWno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "403f15bd-d194-4b4f-91d0-8bdc6f6972d8"
      },
      "source": [
        "import keras.layers\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kNW-4TbQGHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zeropad(x):\n",
        "    y = K.zeros(K.shape(x))\n",
        "    return K.concatenate([x, y],-1)\n",
        "\n",
        "\n",
        "def zeropad_output_shape(input_shape):\n",
        "    shape = list(input_shape)\n",
        "    assert len(shape) == 4\n",
        "    shape[-1] *= 2\n",
        "    return tuple(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfBvaQ4rQFqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization, Convolution2D, MaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Activation, Dropout\n",
        "from keras.layers import Add, ZeroPadding2D, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmFVucw4BwR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wideRes(x,channels,block_number,d_increase=False):\n",
        "    name = str(channels) + str(block_number)\n",
        "    shortcut = x  \n",
        "    if d_increase == True:        \n",
        "        x = Activation('relu')(x)\n",
        "        x = Convolution2D(channels,kernel_size=(3,3),strides=(2,2), padding = \"same\", kernel_initializer = 'he_normal',name='first'+name)(x)        \n",
        "        x = BatchNormalization()(x)\n",
        "        \n",
        "        shortcut = MaxPooling2D((2,2))(shortcut)\n",
        "        #shortcut = keras.layers.concatenate([shortcut,K.zeros(K.shape(shortcut))])\n",
        "        shortcut = Lambda(zeropad, output_shape=zeropad_output_shape)(shortcut)\n",
        "    else:            \n",
        "        x = Activation('relu')(x)\n",
        "        x = Convolution2D(channels, kernel_size=(3,3), padding=\"same\",kernel_initializer='he_normal',name = 'decrease'+name)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(channels, kernel_size=(3,3), padding=\"same\",kernel_initializer='he_normal',name='last'+name)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "        \n",
        "    x = Add()([x,shortcut])    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwuaV_9gb01Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def block_group(x, channels, num_blocks):\n",
        "    for i in range(num_blocks):    \n",
        "        if i==0:    \n",
        "            x = wideRes(x,channels,i,True)            \n",
        "        else:\n",
        "            x = wideRes(x,channels,i,False)    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp8LXUVabo8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def result(x):\n",
        "    input_data=x\n",
        "    k = 2\n",
        "    n = 3\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(32*k, (3,3), strides = (1,1),padding='same', kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(32*k, (3,3), strides = (1,1), padding='same', kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(32*k, (3,3), strides = (2,2), padding='same', kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    \n",
        "    x = MaxPooling2D((3,3),padding='same',strides=(2,2))(x)\n",
        "    \n",
        "\n",
        "    shortcut=x\n",
        "\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64*k, kernel_size=(3,3), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64*k, kernel_size=(3,3), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    shortcut = Lambda(zeropad, output_shape=zeropad_output_shape)(shortcut)\n",
        "    \n",
        "    x = Add()([x,shortcut]) \n",
        "    \n",
        "    x = block_group(x, 128*k, n)    \n",
        "    x = block_group(x, 256*k, n)\n",
        "    x = block_group(x, 512*k, n)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    output_data = Dense(6,activation='softmax')(x)\n",
        "    \n",
        "    model = Model(input_data,output_data)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaIAFpl6cB-q",
        "colab_type": "code",
        "outputId": "9b2a14ca-f3e9-4c86-92ba-5c7f515ea323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "inputs = Input(shape=(160,160,3),dtype='float32')\n",
        "model = result(inputs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fyzEHm8cB5n",
        "colab_type": "code",
        "outputId": "2b71d017-ce39-47ed-eefe-cf736b2f79cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 160, 160, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 160, 160, 3)  12          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 160, 160, 3)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 160, 160, 64) 1792        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 160, 160, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 160, 160, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 160, 160, 64) 36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 160, 160, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 160, 160, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 80, 80, 64)   36928       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 80, 80, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 40, 40, 64)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 40, 40, 64)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 40, 40, 128)  73856       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 40, 40, 128)  512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 40, 40, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  147584      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 40, 40, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 40, 40, 128)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 40, 40, 128)  0           batch_normalization_6[0][0]      \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 40, 40, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "first2560 (Conv2D)              (None, 20, 20, 256)  295168      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 20, 20, 256)  1024        first2560[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 20, 20, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 20, 20, 256)  0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last2560 (Conv2D)               (None, 20, 20, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 20, 20, 256)  1024        last2560[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 20, 20, 256)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decrease2561 (Conv2D)           (None, 20, 20, 256)  590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 256)  1024        decrease2561[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 20, 20, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 256)  0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last2561 (Conv2D)               (None, 20, 20, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 256)  1024        last2561[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 20, 20, 256)  0           batch_normalization_10[0][0]     \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 20, 20, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decrease2562 (Conv2D)           (None, 20, 20, 256)  590080      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 20, 20, 256)  1024        decrease2562[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 20, 20, 256)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 20, 20, 256)  0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last2562 (Conv2D)               (None, 20, 20, 256)  590080      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 20, 20, 256)  1024        last2562[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 20, 20, 256)  0           batch_normalization_12[0][0]     \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 20, 20, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "first5120 (Conv2D)              (None, 10, 10, 512)  1180160     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 10, 10, 512)  2048        first5120[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 10, 10, 512)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 10, 10, 512)  0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last5120 (Conv2D)               (None, 10, 10, 512)  2359808     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 10, 10, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 10, 10, 512)  2048        last5120[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 10, 10, 512)  0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 10, 10, 512)  0           batch_normalization_14[0][0]     \n",
            "                                                                 lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 10, 10, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decrease5121 (Conv2D)           (None, 10, 10, 512)  2359808     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 10, 10, 512)  2048        decrease5121[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 10, 10, 512)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 10, 10, 512)  0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last5121 (Conv2D)               (None, 10, 10, 512)  2359808     activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 10, 10, 512)  2048        last5121[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 10, 10, 512)  0           batch_normalization_16[0][0]     \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 10, 10, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decrease5122 (Conv2D)           (None, 10, 10, 512)  2359808     activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 10, 10, 512)  2048        decrease5122[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 10, 10, 512)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 10, 10, 512)  0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last5122 (Conv2D)               (None, 10, 10, 512)  2359808     activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 10, 10, 512)  2048        last5122[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 10, 10, 512)  0           batch_normalization_18[0][0]     \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 10, 10, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "first10240 (Conv2D)             (None, 5, 5, 1024)   4719616     activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 5, 5, 1024)   4096        first10240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 5, 5, 1024)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 5, 5, 1024)   0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last10240 (Conv2D)              (None, 5, 5, 1024)   9438208     activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 512)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 5, 5, 1024)   4096        last10240[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 5, 5, 1024)   0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 5, 5, 1024)   0           batch_normalization_20[0][0]     \n",
            "                                                                 lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 5, 5, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decrease10241 (Conv2D)          (None, 5, 5, 1024)   9438208     activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 5, 5, 1024)   4096        decrease10241[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 5, 5, 1024)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 5, 5, 1024)   0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last10241 (Conv2D)              (None, 5, 5, 1024)   9438208     activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 5, 5, 1024)   4096        last10241[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 5, 5, 1024)   0           batch_normalization_22[0][0]     \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 5, 5, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decrease10242 (Conv2D)          (None, 5, 5, 1024)   9438208     activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 5, 5, 1024)   4096        decrease10242[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 5, 5, 1024)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 5, 5, 1024)   0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last10242 (Conv2D)              (None, 5, 5, 1024)   9438208     activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 5, 5, 1024)   4096        last10242[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 5, 5, 1024)   0           batch_normalization_24[0][0]     \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 1024)         0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 6)            6150        global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 68,483,474\n",
            "Trainable params: 68,461,068\n",
            "Non-trainable params: 22,406\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6ivRyeRcB2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(shear_range=0.05, width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   horizontal_flip=True, zoom_range=0.2,)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Train, X_Val, Y_Train, Y_Val = train_test_split(X_train,Y_train, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-OpIJkEZm8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXJ_ymfbgn3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr(x):\n",
        "    if x<15:\n",
        "        return 0.01\n",
        "    elif x< 30:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.0001\n",
        "\n",
        "callback_list = [ModelCheckpoint('best.h5',monitor='val_acc',save_best_only=True,save_weights_only=True),\n",
        "                 LearningRateScheduler(lambda x : lr(x),1)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwlbavLWcBxj",
        "colab_type": "code",
        "outputId": "5275adb9-4482-40df-b075-8e094122e0e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "train_generator = train_datagen.flow(X_Train,Y_Train,batch_size=64)\n",
        "hist=model.fit_generator(train_generator,steps_per_epoch=len(X_Train)/64,validation_data=(X_Val,Y_Val),\n",
        "               validation_steps=64,epochs=50,callbacks=callback_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
            "176/175 [==============================] - 79s 449ms/step - loss: 1.4826 - acc: 0.5082 - val_loss: 2.3278 - val_acc: 0.5109\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.01.\n",
            "176/175 [==============================] - 76s 430ms/step - loss: 1.0392 - acc: 0.6319 - val_loss: 1.3420 - val_acc: 0.5191\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.01.\n",
            "176/175 [==============================] - 76s 432ms/step - loss: 0.8324 - acc: 0.6904 - val_loss: 1.1015 - val_acc: 0.6003\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.01.\n",
            "176/175 [==============================] - 76s 432ms/step - loss: 0.6913 - acc: 0.7476 - val_loss: 0.7158 - val_acc: 0.7585\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.01.\n",
            "176/175 [==============================] - 76s 433ms/step - loss: 0.6136 - acc: 0.7774 - val_loss: 0.6796 - val_acc: 0.7353\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.01.\n",
            "176/175 [==============================] - 76s 431ms/step - loss: 0.5629 - acc: 0.7968 - val_loss: 0.5189 - val_acc: 0.8212\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.01.\n",
            " 93/175 [==============>...............] - ETA: 31s - loss: 0.6089 - acc: 0.7987"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJvxnJE-M_g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,loss_ax=plt.subplots(figsize=(12,5))\n",
        "acc_ax=loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'],'indianred',marker='*',label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'],'lightcoral',marker='*',label='val loss')\n",
        "\n",
        "loss_ax.set_ylim([0, 2])\n",
        "\n",
        "\n",
        "acc_ax.plot(hist.history['acc'],'forestgreen',marker='*',label='train accuary')\n",
        "acc_ax.plot(hist.history['val_acc'],'olivedrab',marker='*',label='val accuary')\n",
        "acc_ax.set_ylim([0, 1])\n",
        "\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuzVpMDrDJhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "model.save_weights(\"model_weight.h5\")\n",
        "files.download(\"model_weight.h5\")\n",
        "\n",
        "model.save('wide_model.h5')\n",
        "files.download(\"wide_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8a-LlbfDdQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.predict(X_test,batch_size=128)\n",
        "result = np.argmax(result,axis=1).reshape(-1,1)\n",
        "\n",
        "output = pd.DataFrame(X_id)\n",
        "output['pred_label'] = result\n",
        "output.columns = ['id','pred_label']\n",
        "output = output.set_index('id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAa3xXdoDdsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.to_csv('prediction.csv')\n",
        "\n",
        "\n",
        "files.download(\"prediction.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cji4PiRLDgKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output['count']=1\n",
        "output.groupby('pred_label').sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsu8TLkNOc8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}