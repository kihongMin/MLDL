{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bottle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kihongMin/MLDL/blob/master/bottle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pKRbJlFROk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLVlQ7uBRZti",
        "colab_type": "code",
        "outputId": "9f313ce7-0a73-4c22-f559-4bf90402610f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone \"https://github.com/parrotProj/proj1.git\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'proj1'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/110)\u001b[K\rremote: Counting objects:   1% (2/110)\u001b[K\rremote: Counting objects:   2% (3/110)\u001b[K\rremote: Counting objects:   3% (4/110)\u001b[K\rremote: Counting objects:   4% (5/110)\u001b[K\rremote: Counting objects:   5% (6/110)\u001b[K\rremote: Counting objects:   6% (7/110)\u001b[K\rremote: Counting objects:   7% (8/110)\u001b[K\rremote: Counting objects:   8% (9/110)\u001b[K\rremote: Counting objects:   9% (10/110)\u001b[K\rremote: Counting objects:  10% (11/110)\u001b[K\rremote: Counting objects:  11% (13/110)\u001b[K\rremote: Counting objects:  12% (14/110)\u001b[K\rremote: Counting objects:  13% (15/110)\u001b[K\rremote: Counting objects:  14% (16/110)\u001b[K\rremote: Counting objects:  15% (17/110)\u001b[K\rremote: Counting objects:  16% (18/110)\u001b[K\rremote: Counting objects:  17% (19/110)\u001b[K\rremote: Counting objects:  18% (20/110)\u001b[K\rremote: Counting objects:  19% (21/110)\u001b[K\rremote: Counting objects:  20% (22/110)\u001b[K\rremote: Counting objects:  21% (24/110)\u001b[K\rremote: Counting objects:  22% (25/110)\u001b[K\rremote: Counting objects:  23% (26/110)\u001b[K\rremote: Counting objects:  24% (27/110)\u001b[K\rremote: Counting objects:  25% (28/110)\u001b[K\rremote: Counting objects:  26% (29/110)\u001b[K\rremote: Counting objects:  27% (30/110)\u001b[K\rremote: Counting objects:  28% (31/110)\u001b[K\rremote: Counting objects:  29% (32/110)\u001b[K\rremote: Counting objects:  30% (33/110)\u001b[K\rremote: Counting objects:  31% (35/110)\u001b[K\rremote: Counting objects:  32% (36/110)\u001b[K\rremote: Counting objects:  33% (37/110)\u001b[K\rremote: Counting objects:  34% (38/110)\u001b[K\rremote: Counting objects:  35% (39/110)\u001b[K\rremote: Counting objects:  36% (40/110)\u001b[K\rremote: Counting objects:  37% (41/110)\u001b[K\rremote: Counting objects:  38% (42/110)\u001b[K\rremote: Counting objects:  39% (43/110)\u001b[K\rremote: Counting objects:  40% (44/110)\u001b[K\rremote: Counting objects:  41% (46/110)\u001b[K\rremote: Counting objects:  42% (47/110)\u001b[K\rremote: Counting objects:  43% (48/110)\u001b[K\rremote: Counting objects:  44% (49/110)\u001b[K\rremote: Counting objects:  45% (50/110)\u001b[K\rremote: Counting objects:  46% (51/110)\u001b[K\rremote: Counting objects:  47% (52/110)\u001b[K\rremote: Counting objects:  48% (53/110)\u001b[K\rremote: Counting objects:  49% (54/110)\u001b[K\rremote: Counting objects:  50% (55/110)\u001b[K\rremote: Counting objects:  51% (57/110)\u001b[K\rremote: Counting objects:  52% (58/110)\u001b[K\rremote: Counting objects:  53% (59/110)\u001b[K\rremote: Counting objects:  54% (60/110)\u001b[K\rremote: Counting objects:  55% (61/110)\u001b[K\rremote: Counting objects:  56% (62/110)\u001b[K\rremote: Counting objects:  57% (63/110)\u001b[K\rremote: Counting objects:  58% (64/110)\u001b[K\rremote: Counting objects:  59% (65/110)\u001b[K\rremote: Counting objects:  60% (66/110)\u001b[K\rremote: Counting objects:  61% (68/110)\u001b[K\rremote: Counting objects:  62% (69/110)\u001b[K\rremote: Counting objects:  63% (70/110)\u001b[K\rremote: Counting objects:  64% (71/110)\u001b[K\rremote: Counting objects:  65% (72/110)\u001b[K\rremote: Counting objects:  66% (73/110)\u001b[K\rremote: Counting objects:  67% (74/110)\u001b[K\rremote: Counting objects:  68% (75/110)\u001b[K\rremote: Counting objects:  69% (76/110)\u001b[K\rremote: Counting objects:  70% (77/110)\u001b[K\rremote: Counting objects:  71% (79/110)\u001b[K\rremote: Counting objects:  72% (80/110)\u001b[K\rremote: Counting objects:  73% (81/110)\u001b[K\rremote: Counting objects:  74% (82/110)\u001b[K\rremote: Counting objects:  75% (83/110)\u001b[K\rremote: Counting objects:  76% (84/110)\u001b[K\rremote: Counting objects:  77% (85/110)\u001b[K\rremote: Counting objects:  78% (86/110)\u001b[K\rremote: Counting objects:  79% (87/110)\u001b[K\rremote: Counting objects:  80% (88/110)\u001b[K\rremote: Counting objects:  81% (90/110)\u001b[K\rremote: Counting objects:  82% (91/110)\u001b[K\rremote: Counting objects:  83% (92/110)\u001b[K\rremote: Counting objects:  84% (93/110)\u001b[K\rremote: Counting objects:  85% (94/110)\u001b[K\rremote: Counting objects:  86% (95/110)\u001b[K\rremote: Counting objects:  87% (96/110)\u001b[K\rremote: Counting objects:  88% (97/110)\u001b[K\rremote: Counting objects:  89% (98/110)\u001b[K\rremote: Counting objects:  90% (99/110)\u001b[K\rremote: Counting objects:  91% (101/110)\u001b[K\rremote: Counting objects:  92% (102/110)\u001b[K\rremote: Counting objects:  93% (103/110)\u001b[K\rremote: Counting objects:  94% (104/110)\u001b[K\rremote: Counting objects:  95% (105/110)\u001b[K\rremote: Counting objects:  96% (106/110)\u001b[K\rremote: Counting objects:  97% (107/110)\u001b[K\rremote: Counting objects:  98% (108/110)\u001b[K\rremote: Counting objects:  99% (109/110)\u001b[K\rremote: Counting objects: 100% (110/110)\u001b[K\rremote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 17137 (delta 47), reused 76 (delta 24), pack-reused 17027\u001b[K\n",
            "Receiving objects: 100% (17137/17137), 245.19 MiB | 29.89 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n",
            "Checking out files: 100% (17041/17041), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XxpVF8Raju",
        "colab_type": "code",
        "outputId": "a0018138-8070-4e16-9302-2b5b300c9b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd proj1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/proj1/proj1/proj1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFYYHgDIRbzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Resize\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aou4ay4peRh",
        "colab_type": "code",
        "outputId": "a5d6dfd7-ef40-456c-cabd-4c6b2633d406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "base.ipynb   modifed_res.ipynb  Request.py  \u001b[0m\u001b[01;34mtest\u001b[0m/\n",
            "bottle_2.h5  \u001b[01;34m__pycache__\u001b[0m/       Resize.py   \u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pka2wa-CRc6m",
        "colab_type": "code",
        "outputId": "08a668dc-ce06-4f98-fe97-689f5abe90b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train,Y_train = Resize.train(160)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_size :  160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKkESR28RgEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test,X_id = Resize.test(160)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5LYzePzRmsV",
        "colab_type": "code",
        "outputId": "64859a65-0c75-46f4-df61-a4f51ec32d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y_train = to_categorical(Y_train)\n",
        "print(X_train.shape,Y_train.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14034, 160, 160, 3) (14034, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw8xd2YDRtLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization, Convolution2D, MaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Activation, Dropout\n",
        "from keras.layers import Add, ZeroPadding2D, Flatten\n",
        "\n",
        "def input_block(x):\n",
        "    \n",
        "    x = Convolution2D(32, (3,3), strides = (1,1),padding='same', kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(32, (3,3), strides = (1,1), padding='same', kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZFz0lson_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfTl79JOTJjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bottle_neck(x,channels,d_increase=False):\n",
        "    channel_1,channel_2,channel_3 = channels\n",
        "    shortcut = x  \n",
        "\n",
        "           \n",
        "    if d_increase == True:\n",
        "        x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "        x = Convolution2D(channel_1,kernel_size=(1,1),strides=(1,1),padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        x = Convolution2D(channel_2,kernel_size=(3,3), padding = \"same\", kernel_initializer = 'he_normal')(x)        \n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        \n",
        "        shortcut = Convolution2D(channel_3,kernel_size=(1,1),strides=(2,2),padding='valid',kernel_initializer='he_normal')(shortcut)\n",
        "   \n",
        "    else:\n",
        "        x = Convolution2D(channel_1,kernel_size=(1,1),strides=(1,1),padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        x = Convolution2D(channel_2, kernel_size=(3,3), padding = \"same\", kernel_initializer = 'he_normal')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    #1x1 convolution dim re-increase\n",
        "    x = Convolution2D(channel_3, kernel_size=(1,1), padding = \"valid\", kernel_initializer = 'he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Add()([x,shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03yQuclyRzoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def block_group(x, channels, num_blocks):\n",
        "    for i in range(num_blocks):\n",
        "        if i==0 :\n",
        "            x = bottle_neck(x,channels,True)            \n",
        "        else:\n",
        "            x = bottle_neck(x,channels,)    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP4ViG5TRzyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def result(x, channels=64):\n",
        "    input_data=x            #150 * 150 *3\n",
        "    x = input_block(x)\n",
        "\n",
        "    x = block_group(x, [16,16,64], 3)\n",
        "    \n",
        "    x = block_group(x, [32,32,128], 4)\n",
        "\n",
        "    x = block_group(x, [64,64,256], 8)\n",
        "\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    output_data = Dense(6,activation='softmax')(x)\n",
        "    \n",
        "    model = Model(input_data,output_data)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NSvXHNR1EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input(shape=(160,160,3),dtype='float32')\n",
        "model = result(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZrh5DfFR3GQ",
        "colab_type": "code",
        "outputId": "a3564d5e-9098-4ba5-c7c3-4cb77d0953d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 160, 160, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 160, 160, 32) 896         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 160, 160, 32) 128         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 160, 160, 32) 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 160, 160, 32) 9248        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 160, 160, 32) 128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 160, 160, 32) 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 80, 80, 32)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 80, 80, 16)   528         max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 80, 80, 16)   64          conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 80, 80, 16)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 80, 80, 16)   2320        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 80, 80, 16)   64          conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 80, 80, 16)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 80, 80, 64)   1088        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 80, 80, 64)   2112        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 80, 80, 64)   256         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 80, 80, 64)   256         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 80, 80, 64)   0           batch_normalization_67[0][0]     \n",
            "                                                                 batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 80, 80, 64)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 80, 80, 16)   1040        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 80, 80, 16)   64          conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 80, 80, 16)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 80, 80, 16)   2320        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 80, 80, 16)   64          conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 80, 80, 16)   0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 80, 80, 64)   1088        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 80, 80, 64)   256         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 80, 80, 64)   256         activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 80, 80, 64)   0           batch_normalization_71[0][0]     \n",
            "                                                                 batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 80, 80, 64)   0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 80, 80, 16)   1040        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 80, 80, 16)   64          conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 80, 80, 16)   0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 80, 80, 16)   2320        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 80, 80, 16)   64          conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 80, 80, 16)   0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 80, 80, 64)   1088        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 80, 80, 64)   256         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 80, 80, 64)   256         activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 80, 80, 64)   0           batch_normalization_75[0][0]     \n",
            "                                                                 batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 80, 80, 64)   0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 40, 40, 64)   0           activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 40, 40, 32)   2080        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 40, 40, 32)   128         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 40, 40, 32)   0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 40, 40, 32)   9248        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 40, 40, 32)   128         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 40, 40, 32)   0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 40, 40, 128)  4224        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 40, 40, 128)  8320        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 40, 40, 128)  512         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 40, 40, 128)  512         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 40, 40, 128)  0           batch_normalization_79[0][0]     \n",
            "                                                                 batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 40, 40, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 40, 40, 32)   4128        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 40, 40, 32)   128         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 40, 40, 32)   0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 40, 40, 32)   9248        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 40, 40, 32)   128         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 40, 40, 32)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 40, 40, 128)  4224        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 40, 40, 128)  512         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 40, 40, 128)  512         activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 40, 40, 128)  0           batch_normalization_83[0][0]     \n",
            "                                                                 batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 40, 40, 128)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 40, 40, 32)   4128        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 40, 40, 32)   128         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 40, 40, 32)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 40, 40, 32)   9248        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 40, 40, 32)   128         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 40, 40, 32)   0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 40, 40, 128)  4224        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 40, 40, 128)  512         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 40, 40, 128)  512         activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 40, 40, 128)  0           batch_normalization_87[0][0]     \n",
            "                                                                 batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 40, 40, 128)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 40, 40, 32)   4128        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 40, 40, 32)   128         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 40, 40, 32)   0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 40, 40, 32)   9248        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 40, 40, 32)   128         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 40, 40, 32)   0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 40, 40, 128)  4224        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 40, 40, 128)  512         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 40, 40, 128)  512         activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 40, 40, 128)  0           batch_normalization_91[0][0]     \n",
            "                                                                 batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 40, 40, 128)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 20, 20, 128)  0           activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 20, 20, 64)   8256        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 20, 20, 64)   256         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 20, 20, 64)   0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 20, 20, 64)   36928       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 20, 20, 64)   256         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 20, 20, 64)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 20, 20, 256)  16640       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 20, 20, 256)  33024       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 20, 20, 256)  1024        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 20, 20, 256)  1024        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 20, 20, 256)  0           batch_normalization_95[0][0]     \n",
            "                                                                 batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 20, 20, 256)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 20, 20, 64)   16448       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 20, 20, 64)   256         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 20, 20, 64)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 20, 20, 64)   36928       activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 20, 20, 64)   256         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 20, 20, 64)   0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 20, 20, 256)  16640       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 20, 20, 256)  1024        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 20, 20, 256)  1024        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 20, 20, 256)  0           batch_normalization_99[0][0]     \n",
            "                                                                 batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 20, 20, 256)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 20, 20, 64)   16448       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 20, 20, 64)   256         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 20, 20, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 20, 20, 64)   36928       activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 20, 20, 64)   256         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 20, 20, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 20, 20, 256)  16640       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 20, 20, 256)  1024        conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 20, 20, 256)  1024        activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 20, 20, 256)  0           batch_normalization_103[0][0]    \n",
            "                                                                 batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 20, 20, 256)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 20, 20, 64)   16448       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 20, 20, 64)   256         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 20, 20, 64)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 20, 20, 64)   36928       activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 20, 20, 64)   256         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 20, 20, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 20, 20, 256)  16640       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 20, 20, 256)  1024        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 20, 20, 256)  1024        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 20, 20, 256)  0           batch_normalization_107[0][0]    \n",
            "                                                                 batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 20, 20, 256)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 20, 20, 64)   16448       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 20, 20, 64)   256         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 20, 20, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 20, 20, 64)   36928       activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 20, 20, 64)   256         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 20, 20, 64)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 20, 20, 256)  16640       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 20, 20, 256)  1024        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 20, 20, 256)  1024        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 20, 20, 256)  0           batch_normalization_111[0][0]    \n",
            "                                                                 batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 20, 20, 256)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 20, 20, 64)   16448       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 20, 20, 64)   256         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 20, 20, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 20, 20, 64)   36928       activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 20, 20, 64)   256         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 20, 20, 64)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 20, 20, 256)  16640       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 20, 20, 256)  1024        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 20, 20, 256)  1024        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 20, 20, 256)  0           batch_normalization_115[0][0]    \n",
            "                                                                 batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 20, 20, 256)  0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 20, 20, 64)   16448       activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 20, 20, 64)   256         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 20, 20, 64)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 20, 20, 64)   36928       activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 20, 20, 64)   256         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 20, 20, 64)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 20, 20, 256)  16640       activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 20, 20, 256)  1024        conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 20, 20, 256)  1024        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 20, 20, 256)  0           batch_normalization_119[0][0]    \n",
            "                                                                 batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 20, 20, 256)  0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 20, 20, 64)   16448       activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 20, 20, 64)   256         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 20, 20, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 20, 20, 64)   36928       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 20, 20, 64)   256         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 20, 20, 64)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 20, 20, 256)  16640       activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 20, 20, 256)  1024        conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 20, 20, 256)  1024        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 20, 20, 256)  0           batch_normalization_123[0][0]    \n",
            "                                                                 batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 20, 20, 256)  0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 256)          0           activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            1542        global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 716,038\n",
            "Trainable params: 702,150\n",
            "Non-trainable params: 13,888\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5hqWlWRPK-S",
        "colab_type": "code",
        "outputId": "56763417-5887-4e58-aae3-214c083c6548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "base.ipynb   modifed_res.ipynb  Request.py  \u001b[0m\u001b[01;34mtest\u001b[0m/\n",
            "bottle_2.h5  \u001b[01;34m__pycache__\u001b[0m/       Resize.py   \u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYF1NmmWOwjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('bottle_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZozR4f5R5pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(shear_range=0.05, width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   horizontal_flip=True, zoom_range=0.2)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_Val, Y_train, Y_Val = train_test_split(X_train,Y_train, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50GvzY-cfN6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d3091b4-ac26-4905-b915-c11a57f94f62"
      },
      "source": [
        "train_generator = train_datagen.flow(X_train,Y_train,batch_size=128)\n",
        "hist=model.fit_generator(train_generator,steps_per_epoch=len(X_train)/128,validation_data=(X_Val,Y_Val),\n",
        "               validation_steps=32,epochs=90)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/90\n",
            "88/87 [==============================] - 98s 1s/step - loss: 0.2658 - acc: 0.9070 - val_loss: 0.3389 - val_acc: 0.8828\n",
            "Epoch 2/90\n",
            "88/87 [==============================] - 78s 881ms/step - loss: 0.2417 - acc: 0.9124 - val_loss: 0.3008 - val_acc: 0.8921\n",
            "Epoch 3/90\n",
            "88/87 [==============================] - 79s 894ms/step - loss: 0.2243 - acc: 0.9202 - val_loss: 0.3802 - val_acc: 0.8742\n",
            "Epoch 4/90\n",
            "88/87 [==============================] - 79s 893ms/step - loss: 0.2254 - acc: 0.9207 - val_loss: 0.4160 - val_acc: 0.8557\n",
            "Epoch 5/90\n",
            "88/87 [==============================] - 80s 907ms/step - loss: 0.2216 - acc: 0.9207 - val_loss: 0.2910 - val_acc: 0.8988\n",
            "Epoch 6/90\n",
            "88/87 [==============================] - 80s 906ms/step - loss: 0.2136 - acc: 0.9209 - val_loss: 0.4260 - val_acc: 0.8753\n",
            "Epoch 7/90\n",
            "88/87 [==============================] - 80s 910ms/step - loss: 0.2022 - acc: 0.9276 - val_loss: 0.3741 - val_acc: 0.8757\n",
            "Epoch 8/90\n",
            "88/87 [==============================] - 80s 914ms/step - loss: 0.2021 - acc: 0.9266 - val_loss: 0.5117 - val_acc: 0.8347\n",
            "Epoch 9/90\n",
            "88/87 [==============================] - 80s 908ms/step - loss: 0.1955 - acc: 0.9304 - val_loss: 0.3850 - val_acc: 0.8732\n",
            "Epoch 10/90\n",
            "88/87 [==============================] - 80s 908ms/step - loss: 0.1978 - acc: 0.9274 - val_loss: 0.3652 - val_acc: 0.8767\n",
            "Epoch 11/90\n",
            "88/87 [==============================] - 80s 911ms/step - loss: 0.1928 - acc: 0.9283 - val_loss: 0.3457 - val_acc: 0.8853\n",
            "Epoch 12/90\n",
            "88/87 [==============================] - 80s 910ms/step - loss: 0.1878 - acc: 0.9294 - val_loss: 0.3133 - val_acc: 0.8960\n",
            "Epoch 13/90\n",
            "88/87 [==============================] - 80s 912ms/step - loss: 0.1706 - acc: 0.9364 - val_loss: 0.3670 - val_acc: 0.8757\n",
            "Epoch 14/90\n",
            "88/87 [==============================] - 81s 916ms/step - loss: 0.1760 - acc: 0.9349 - val_loss: 0.3314 - val_acc: 0.8949\n",
            "Epoch 15/90\n",
            "88/87 [==============================] - 80s 914ms/step - loss: 0.1752 - acc: 0.9356 - val_loss: 0.4637 - val_acc: 0.8671\n",
            "Epoch 16/90\n",
            "88/87 [==============================] - 80s 915ms/step - loss: 0.1658 - acc: 0.9379 - val_loss: 0.3178 - val_acc: 0.8978\n",
            "Epoch 17/90\n",
            "88/87 [==============================] - 80s 914ms/step - loss: 0.1672 - acc: 0.9372 - val_loss: 0.3764 - val_acc: 0.8867\n",
            "Epoch 18/90\n",
            "88/87 [==============================] - 83s 939ms/step - loss: 0.1477 - acc: 0.9450 - val_loss: 0.3826 - val_acc: 0.8945\n",
            "Epoch 19/90\n",
            "88/87 [==============================] - 81s 921ms/step - loss: 0.1604 - acc: 0.9398 - val_loss: 0.4878 - val_acc: 0.8668\n",
            "Epoch 20/90\n",
            "88/87 [==============================] - 82s 928ms/step - loss: 0.1545 - acc: 0.9421 - val_loss: 0.3028 - val_acc: 0.9024\n",
            "Epoch 21/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.1450 - acc: 0.9465 - val_loss: 0.3482 - val_acc: 0.8938\n",
            "Epoch 22/90\n",
            "88/87 [==============================] - 81s 924ms/step - loss: 0.1452 - acc: 0.9476 - val_loss: 0.6775 - val_acc: 0.8269\n",
            "Epoch 23/90\n",
            "88/87 [==============================] - 82s 929ms/step - loss: 0.1445 - acc: 0.9466 - val_loss: 0.5790 - val_acc: 0.8429\n",
            "Epoch 24/90\n",
            "88/87 [==============================] - 81s 922ms/step - loss: 0.1438 - acc: 0.9465 - val_loss: 0.4250 - val_acc: 0.8682\n",
            "Epoch 25/90\n",
            "88/87 [==============================] - 81s 926ms/step - loss: 0.1364 - acc: 0.9497 - val_loss: 0.4050 - val_acc: 0.8810\n",
            "Epoch 26/90\n",
            "88/87 [==============================] - 82s 927ms/step - loss: 0.1373 - acc: 0.9493 - val_loss: 0.3947 - val_acc: 0.8796\n",
            "Epoch 27/90\n",
            "88/87 [==============================] - 81s 925ms/step - loss: 0.1405 - acc: 0.9488 - val_loss: 0.3685 - val_acc: 0.8871\n",
            "Epoch 28/90\n",
            "88/87 [==============================] - 81s 922ms/step - loss: 0.1354 - acc: 0.9507 - val_loss: 0.4247 - val_acc: 0.8757\n",
            "Epoch 29/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.1303 - acc: 0.9509 - val_loss: 0.4295 - val_acc: 0.8714\n",
            "Epoch 30/90\n",
            "88/87 [==============================] - 82s 927ms/step - loss: 0.1265 - acc: 0.9535 - val_loss: 0.5624 - val_acc: 0.8518\n",
            "Epoch 31/90\n",
            "88/87 [==============================] - 81s 920ms/step - loss: 0.1254 - acc: 0.9531 - val_loss: 0.4371 - val_acc: 0.8778\n",
            "Epoch 32/90\n",
            "88/87 [==============================] - 81s 924ms/step - loss: 0.1202 - acc: 0.9558 - val_loss: 0.4306 - val_acc: 0.8696\n",
            "Epoch 33/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.1101 - acc: 0.9598 - val_loss: 0.4229 - val_acc: 0.8746\n",
            "Epoch 34/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.1197 - acc: 0.9560 - val_loss: 0.4039 - val_acc: 0.8864\n",
            "Epoch 35/90\n",
            "88/87 [==============================] - 81s 925ms/step - loss: 0.1140 - acc: 0.9564 - val_loss: 0.3545 - val_acc: 0.8956\n",
            "Epoch 36/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.1151 - acc: 0.9586 - val_loss: 0.4138 - val_acc: 0.8935\n",
            "Epoch 37/90\n",
            "88/87 [==============================] - 81s 924ms/step - loss: 0.1005 - acc: 0.9637 - val_loss: 0.4038 - val_acc: 0.8864\n",
            "Epoch 38/90\n",
            "88/87 [==============================] - 81s 921ms/step - loss: 0.1065 - acc: 0.9608 - val_loss: 0.4861 - val_acc: 0.8689\n",
            "Epoch 39/90\n",
            "88/87 [==============================] - 81s 922ms/step - loss: 0.1144 - acc: 0.9566 - val_loss: 0.4332 - val_acc: 0.8856\n",
            "Epoch 40/90\n",
            "88/87 [==============================] - 81s 921ms/step - loss: 0.1040 - acc: 0.9615 - val_loss: 0.3572 - val_acc: 0.9045\n",
            "Epoch 41/90\n",
            "88/87 [==============================] - 81s 920ms/step - loss: 0.1040 - acc: 0.9624 - val_loss: 0.6501 - val_acc: 0.8408\n",
            "Epoch 42/90\n",
            "88/87 [==============================] - 81s 920ms/step - loss: 0.1040 - acc: 0.9621 - val_loss: 0.5111 - val_acc: 0.8693\n",
            "Epoch 43/90\n",
            "88/87 [==============================] - 81s 921ms/step - loss: 0.0976 - acc: 0.9639 - val_loss: 0.5387 - val_acc: 0.8643\n",
            "Epoch 44/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.0985 - acc: 0.9651 - val_loss: 0.5917 - val_acc: 0.8532\n",
            "Epoch 45/90\n",
            "88/87 [==============================] - 81s 924ms/step - loss: 0.1016 - acc: 0.9621 - val_loss: 0.3834 - val_acc: 0.8921\n",
            "Epoch 46/90\n",
            "88/87 [==============================] - 83s 948ms/step - loss: 0.0987 - acc: 0.9636 - val_loss: 0.4597 - val_acc: 0.8885\n",
            "Epoch 47/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.0973 - acc: 0.9620 - val_loss: 0.5068 - val_acc: 0.8757\n",
            "Epoch 48/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.0936 - acc: 0.9664 - val_loss: 0.5085 - val_acc: 0.8714\n",
            "Epoch 49/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.0947 - acc: 0.9676 - val_loss: 0.3797 - val_acc: 0.8949\n",
            "Epoch 50/90\n",
            "88/87 [==============================] - 81s 925ms/step - loss: 0.0938 - acc: 0.9666 - val_loss: 0.3735 - val_acc: 0.9002\n",
            "Epoch 51/90\n",
            "88/87 [==============================] - 81s 922ms/step - loss: 0.0801 - acc: 0.9700 - val_loss: 0.3751 - val_acc: 0.8938\n",
            "Epoch 52/90\n",
            "88/87 [==============================] - 83s 946ms/step - loss: 0.0878 - acc: 0.9688 - val_loss: 0.4681 - val_acc: 0.8910\n",
            "Epoch 53/90\n",
            "88/87 [==============================] - 81s 924ms/step - loss: 0.0836 - acc: 0.9702 - val_loss: 0.3835 - val_acc: 0.9067\n",
            "Epoch 54/90\n",
            "88/87 [==============================] - 81s 925ms/step - loss: 0.0919 - acc: 0.9659 - val_loss: 0.4673 - val_acc: 0.8803\n",
            "Epoch 55/90\n",
            "88/87 [==============================] - 82s 926ms/step - loss: 0.0801 - acc: 0.9713 - val_loss: 0.5228 - val_acc: 0.8721\n",
            "Epoch 56/90\n",
            "88/87 [==============================] - 81s 922ms/step - loss: 0.0741 - acc: 0.9730 - val_loss: 0.5286 - val_acc: 0.8778\n",
            "Epoch 57/90\n",
            "88/87 [==============================] - 81s 923ms/step - loss: 0.0774 - acc: 0.9705 - val_loss: 0.4689 - val_acc: 0.8782\n",
            "Epoch 58/90\n",
            "88/87 [==============================] - 81s 918ms/step - loss: 0.0780 - acc: 0.9733 - val_loss: 0.4598 - val_acc: 0.8985\n",
            "Epoch 59/90\n",
            "88/87 [==============================] - 80s 913ms/step - loss: 0.0808 - acc: 0.9699 - val_loss: 0.4730 - val_acc: 0.8881\n",
            "Epoch 60/90\n",
            "88/87 [==============================] - 80s 910ms/step - loss: 0.0789 - acc: 0.9716 - val_loss: 0.5398 - val_acc: 0.8678\n",
            "Epoch 61/90\n",
            "88/87 [==============================] - 80s 904ms/step - loss: 0.0684 - acc: 0.9761 - val_loss: 0.5638 - val_acc: 0.8639\n",
            "Epoch 62/90\n",
            "88/87 [==============================] - 79s 903ms/step - loss: 0.0752 - acc: 0.9740 - val_loss: 0.4700 - val_acc: 0.8753\n",
            "Epoch 63/90\n",
            "88/87 [==============================] - 79s 902ms/step - loss: 0.0670 - acc: 0.9749 - val_loss: 0.5205 - val_acc: 0.8789\n",
            "Epoch 64/90\n",
            "88/87 [==============================] - 79s 901ms/step - loss: 0.0819 - acc: 0.9706 - val_loss: 0.5963 - val_acc: 0.8693\n",
            "Epoch 65/90\n",
            "88/87 [==============================] - 79s 901ms/step - loss: 0.0732 - acc: 0.9747 - val_loss: 0.5139 - val_acc: 0.8824\n",
            "Epoch 66/90\n",
            "88/87 [==============================] - 79s 897ms/step - loss: 0.0763 - acc: 0.9724 - val_loss: 0.5808 - val_acc: 0.8650\n",
            "Epoch 67/90\n",
            "88/87 [==============================] - 79s 893ms/step - loss: 0.0716 - acc: 0.9748 - val_loss: 0.4123 - val_acc: 0.8953\n",
            "Epoch 68/90\n",
            "88/87 [==============================] - 79s 893ms/step - loss: 0.0623 - acc: 0.9778 - val_loss: 0.4677 - val_acc: 0.8942\n",
            "Epoch 69/90\n",
            "88/87 [==============================] - 78s 889ms/step - loss: 0.0655 - acc: 0.9773 - val_loss: 0.5469 - val_acc: 0.8728\n",
            "Epoch 70/90\n",
            "88/87 [==============================] - 78s 889ms/step - loss: 0.0751 - acc: 0.9730 - val_loss: 0.4480 - val_acc: 0.8846\n",
            "Epoch 71/90\n",
            "88/87 [==============================] - 78s 891ms/step - loss: 0.0730 - acc: 0.9746 - val_loss: 0.4555 - val_acc: 0.8931\n",
            "Epoch 72/90\n",
            "88/87 [==============================] - 78s 887ms/step - loss: 0.0722 - acc: 0.9742 - val_loss: 0.4885 - val_acc: 0.8846\n",
            "Epoch 73/90\n",
            "88/87 [==============================] - 78s 892ms/step - loss: 0.0709 - acc: 0.9756 - val_loss: 0.5094 - val_acc: 0.8810\n",
            "Epoch 74/90\n",
            "88/87 [==============================] - 78s 886ms/step - loss: 0.0695 - acc: 0.9764 - val_loss: 0.5218 - val_acc: 0.8750\n",
            "Epoch 75/90\n",
            "88/87 [==============================] - 78s 884ms/step - loss: 0.0539 - acc: 0.9819 - val_loss: 0.5137 - val_acc: 0.8963\n",
            "Epoch 76/90\n",
            "88/87 [==============================] - 78s 886ms/step - loss: 0.0529 - acc: 0.9810 - val_loss: 0.5738 - val_acc: 0.8685\n",
            "Epoch 77/90\n",
            "88/87 [==============================] - 78s 887ms/step - loss: 0.0613 - acc: 0.9767 - val_loss: 0.5831 - val_acc: 0.8849\n",
            "Epoch 78/90\n",
            "88/87 [==============================] - 78s 884ms/step - loss: 0.0611 - acc: 0.9782 - val_loss: 0.5546 - val_acc: 0.8888\n",
            "Epoch 79/90\n",
            "88/87 [==============================] - 78s 882ms/step - loss: 0.0686 - acc: 0.9745 - val_loss: 0.4713 - val_acc: 0.8953\n",
            "Epoch 80/90\n",
            "88/87 [==============================] - 78s 883ms/step - loss: 0.0616 - acc: 0.9768 - val_loss: 0.4921 - val_acc: 0.8945\n",
            "Epoch 81/90\n",
            "88/87 [==============================] - 78s 887ms/step - loss: 0.0693 - acc: 0.9767 - val_loss: 0.5595 - val_acc: 0.8682\n",
            "Epoch 82/90\n",
            "88/87 [==============================] - 78s 886ms/step - loss: 0.0728 - acc: 0.9731 - val_loss: 0.6576 - val_acc: 0.8639\n",
            "Epoch 83/90\n",
            "88/87 [==============================] - 78s 883ms/step - loss: 0.0622 - acc: 0.9767 - val_loss: 0.6965 - val_acc: 0.8593\n",
            "Epoch 84/90\n",
            "88/87 [==============================] - 78s 883ms/step - loss: 0.0505 - acc: 0.9827 - val_loss: 0.5279 - val_acc: 0.8757\n",
            "Epoch 85/90\n",
            "88/87 [==============================] - 77s 880ms/step - loss: 0.0577 - acc: 0.9795 - val_loss: 0.5557 - val_acc: 0.8921\n",
            "Epoch 86/90\n",
            "88/87 [==============================] - 78s 881ms/step - loss: 0.0540 - acc: 0.9809 - val_loss: 0.4810 - val_acc: 0.8888\n",
            "Epoch 87/90\n",
            "88/87 [==============================] - 78s 887ms/step - loss: 0.0485 - acc: 0.9832 - val_loss: 0.4562 - val_acc: 0.9017\n",
            "Epoch 88/90\n",
            "88/87 [==============================] - 78s 882ms/step - loss: 0.0608 - acc: 0.9780 - val_loss: 0.5189 - val_acc: 0.8842\n",
            "Epoch 89/90\n",
            "88/87 [==============================] - 78s 885ms/step - loss: 0.0578 - acc: 0.9800 - val_loss: 0.5063 - val_acc: 0.8892\n",
            "Epoch 90/90\n",
            "88/87 [==============================] - 78s 884ms/step - loss: 0.0657 - acc: 0.9764 - val_loss: 0.7987 - val_acc: 0.8400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxBVgNTtOccp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2d19b41-e472-4f1c-c68c-bf2f83acbcc3"
      },
      "source": [
        "hist."
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f85b3ea3470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufSz5E2g2-oE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "20cc0cad-25b0-4114-d217-67addd6284c7"
      },
      "source": [
        "fig,loss_ax=plt.subplots(figsize=(12,5))\n",
        "acc_ax=loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'],'indianred',marker='*',label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'],'lightcoral',marker='*',label='val loss')\n",
        "\n",
        "\n",
        "loss_ax.set_ylim([0, 2])\n",
        "\n",
        "\n",
        "acc_ax.plot(hist.history['acc'],'forestgreen',marker='*',label='train accuary')\n",
        "acc_ax.plot(hist.history['val_acc'],'olivedrab',marker='*',label='val accuary')\n",
        "acc_ax.set_ylim([0, 1])\n",
        "\n",
        "\n",
        "\n",
        "loss_ax.s\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-6cd17c431dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mloss_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no attribute 's'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAEzCAYAAABwnLYVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1NE99sfQXQFsn0oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPJNE_HgBn69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "model.save_weights(\"bottle_2.h5\")\n",
        "files.download(\"bottle_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Kg9m6Q3Nlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "1c59b997-0956-4058-8f6b-2f1327b24deb"
      },
      "source": [
        "result = model.predict(X_test,batch_size=128)\n",
        "result = np.argmax(result,axis=1).reshape(-1,1)\n",
        "\n",
        "output = pd.DataFrame(X_id)\n",
        "output['pred_label'] = result\n",
        "output.columns = ['id','pred_label']\n",
        "output.set_index('id')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20485</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20843</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23465</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20564</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24169</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21611</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20276</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21720</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21811</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21306</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       pred_label\n",
              "id               \n",
              "20485           5\n",
              "20843           1\n",
              "23465           5\n",
              "20564           1\n",
              "24169           0\n",
              "...           ...\n",
              "21611           3\n",
              "20276           0\n",
              "21720           5\n",
              "21811           2\n",
              "21306           1\n",
              "\n",
              "[3000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfZHFB5i3URf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.to_csv('prediction.csv')\n",
        "\n",
        "\n",
        "files.download(\"prediction.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbgxb3ng3XUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "b97a58aa-0808-4289-cfe1-9f019ffdc85b"
      },
      "source": [
        "output['count']=1\n",
        "output.groupby('pred_label').sum()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            count\n",
              "pred_label       \n",
              "0             402\n",
              "1             329\n",
              "2             631\n",
              "3             648\n",
              "4             523\n",
              "5             467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBdneerE3ZCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('bottle_model.h5')\n",
        "\n",
        "files.download(\"bottle_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxUGuNWAt7pD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}